\documentclass[a4paper]{scrreprt}

% Uncomment to optimize for double-sided printing.
% \KOMAoptions{twoside}

% Set binding correction manually, if known.
% \KOMAoptions{BCOR=2cm}

% Localization options
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

% Enhanced verbatim sections. We're mainly interested in
% \verbatiminput though.
\usepackage{verbatim}

% PDF-compatible landscape mode.
% Makes PDF viewers show the page rotated by 90Â°.
\usepackage{pdflscape}

% Advanced tables
\usepackage{tabu}
\usepackage{longtable}

% Fancy tablerules
\usepackage{booktabs}

% Graphics
\usepackage{graphicx}

% Current time
\usepackage[useregional=numeric]{datetime2}

% Float barriers.
% Automatically add a FloatBarrier to each \section
\usepackage[section]{placeins}

% Custom header and footer
\usepackage{fancyhdr}

\usepackage{geometry}
\usepackage{layout}

% Math tools
\usepackage{mathtools}
% Math symbols
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{amsthm}

\DeclarePairedDelimiter\abs{\lvert}{\rvert}

\pagestyle{plain}
% \fancyhf{}
% \lhead{}
% \lfoot{}
% \rfoot{}
% 
% Source code & highlighting
\usepackage{listings}

% Convenience commands
\newcommand{\mailsubject}{451670- Algorithmen, Wahrscheinlichkeit, Informationen - Series 7}
\newcommand{\maillink}[1]{\href{mailto:#1?subject=\mailsubject}
                               {#1}}

% Should use this command wherever the print date is mentioned.
\newcommand{\printdate}{\today}

\subject{451670 - Algorithmen, Wahrscheinlichkeit, Informationen}
\title{Series 8}

\author{Michael Senn \maillink{michael.senn@students.unibe.ch} - 16-126-880}

\date{\printdate}

% Needs to be the last command in the preamble, for one reason or
% another. 
\usepackage{hyperref}


\begin{document}
\maketitle


\setcounter{chapter}{7}
\chapter{Series 8}

\section{Probability of given vertex selected by algorithm}

The algorithm $S$ will select a given vertex $v \in V$ exactly if in its first
step it selects an edge $e \in E$ of which one component is equal to $v$, and
in its second step choses $v$ rather than the second component of the selected
edge.

As there are a total of $m$ edges, of which $deg(v)$ have $v$ as one of their 
components, the probability is given as:

\begin{align*}
	P[S = v] & = \frac{deg(v)}{m} \cdot \frac{1}{2} \\
		 & = \frac{deg(v)}{2m}
\end{align*}

\section{Expected value of size estimator}

Let $l(v) := \frac{2m}{deg(v)}$. By the definition and properties of the
expected value, $E[l(S)]$ is given as:

\begin{align*}
	E[l(S)] & = \sum_{s \in S}{P(S = s) \cdot l(s)} \\
		& = \sum_{s \in S}{\frac{deg(s)}{2m} \cdot \frac{2m}{deg(s)}} \\
		& = \sum_{s \in S}{1} \\
		& = n
\end{align*}

Hence, $l(v)$ is an unbiased estimator for $n$, the size of the graph.

\section{Variance of size estimator}

We aim to show that $Var(l(S)) \leq n^2d$.

\begin{proof}
  \begin{align*}
    E[l(S)^2] & = \sum_{s \in S}{P(S = s) \cdot l(S)^2} \\
    & = \sum_{s \in S}{\frac{deg(s)}{2m} \cdot \left(\frac{2m}{deg(s)}\right)^2} \\
    & = \sum_{s \in S}{\frac{2m}{deg(s)}} \\
    & = 2m \sum_{s \in S}{\frac{1}{deg(s)}}
  \end{align*}

  Hence:

  \begin{align*}
    Var(l(S)) & = E[l(S)^2] - E[l(S)]^2 \\
              & = 2m \sum_{s \in S}{\left(\frac{1}{deg(s)}\right)} - n^2 \\
    \intertext{As $deg(v) \leq d\ \forall v \in V$, and $2m = \sum_{v \in V}{deg(v)} \leq \sum_{v \in V}{d} = nd$}
    & \leq nd \sum_{s \in S}{\left(\frac{1}{deg(s)}\right)} - n^2 \\
    & \leq nd \sum_{s \in S}{\left(1\right)} - n^2 \\
    & \leq ndn - n^2 \\
    & = n^2d - n^2 \\
    & \leq n^2d
  \end{align*}
\end{proof}

\section{Variance of the mean}

Let $Z := \frac{1}{t} \sum_{i=1}^t{l(S_i)}$, where $S_i$ are IID. We aim to
show that $Var(Z) \leq \frac{n^2 d}{t}$.

\begin{proof}
  \begin{align*}
    Var(Z) & = Var\left(\frac{1}{t} \sum_{i=1}^t{l(S_i)}\right) \\
    \intertext{$Var(aX) = a^2 Var(X)$}
    & = \frac{1}{t^2} Var\left(\sum_{i=1}^t{l(S_i)}\right) \\
    \intertext{By the independence of $S_i$}
    & = \frac{1}{t^2} \sum_{i=1}^t{Var(l(S_i))} \\
    \intertext{As per above}
    & \leq \frac{1}{t^2} \sum_{i=1}^t{n^2 d} \\
    & = \frac{n^2 d}{t}
  \end{align*}
\end{proof}

\section{Limiting estimator error via sample size}

From corollary 3.7 in the book we know that we can bound the deviation of a
random variable from its expectation as:
\[
	P[\abs{X - E[X]} \geq t \cdot E[X]] \leq \frac{Var(X)}{t^2 (E[X])^2}
\]

As such, for $0 < \epsilon \leq 1$, $0 < \delta \leq 1$:
\begin{align*}
	P[\abs{Z - n} \geq \epsilon n] & \leq \frac{Var(Z)}{\epsilon^2 n^2} \\
	\intertext{Using the upper bound of the variance from above}
	& \leq \frac{n^2 d}{t \epsilon^2 n^2} \\
	& = \frac{d}{t \epsilon^2}
\end{align*}

We can then get a lower bound for $t$:
\begin{align*}
	& \frac{d}{t \epsilon^2} \leq \delta \\
	\Rightarrow & t \geq \frac{d}{\epsilon^2 \delta}
\end{align*}

\end{document}

