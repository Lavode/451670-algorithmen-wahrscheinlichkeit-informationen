# 2. Zufallsvariablen und Erwaruntgswerte (2019-03-11)

## Def Bedingter Erwartungswert

- E[X | Y=y] = Sum over x: x * P(X=x | Y=y)

### Bsp

Sei:
X1, X2 ~ Un([1, k]), Z := X1 + X2

Dann:
E[Xi] = (k+1)/2
E[Z] = E[X1 + X2] = E[X1] + E[X2] = k+1

Und:
E[Z | X1 = 1] = 1 + E[X2] = 1 + (k+1)/2

### Theorem ZV X, Y

E[X] = Sum over y: P(Y=y) E[X | Y=y]

#### Bew

```
E[X] = Sum over y: P(Y=y) * Sum over x: x * P(X=x | Y=y)
= Sum over x: Sum over y: x * P(Y=y) * P(X=X | Y=y)^x
= Sum over x: Sum over y: x * P(X=x, Y=y) // Def der bedingten W'keit
= Sum over x: Sum over y: x * P(X=x) * P(Y=y | X=x) // Nochmals
= Sum over x: x * P(X=x) * Sum over y: P(Y=y | X=x)
= Sum over x: x * P(X=x) * 1
= E[X]
```

Mind: E[X | Y=y] != E[X|Y]
- Bedingter Erwartungswert gegeben Ereignis vs Erwartungswert bedingt auf eine
  ZV
- Skalar vs ZV

### Def Bedingter Erwartungswert gegeben eine ZV

E[X | Y] bezeichnet eine ZV A = f(Y), welche mit P(Y=y) den Wert a = E[X | Y=y]
annimmt.

#### Bsp

```
Z = X1 + X2, Xi ~ Un([1, k])
E[Z | X1 = x1] = Sum over z = 2 to 2k: z * P(Z=z | X1=x1)
= Sum over x2 = 1 to k: (x1 + x2) * P(Z=z | X1=x1)
= x1 + Sum over x2 = 1 to k: x2 * P(X2 = x2)
= x1 + E[X2] = x1 + (k + 1)/2
```

Damit
```
P(X1=x1) = 1/k

E[E[Z | X1]] = Sum over X1: E[Z | X1=x1] * P(X1=x1)
= Sum over X1: 1/k * (x1 + (k+1)/2)
= Sum over i = 1 to k: 1/k * x1 + (k+1)/2
= k+1 = E[Z]
```

## Algorithmus: Auswahl einer zufälligen Permutation

Gegeben: random(1, k) -> Zufällige ganze Zahl in [1, k]

Algorithmus 1: O(n^2)
```
for i = 1 .. n, do
    do 
        j := random(1, n)
    while j in {pi_1, ..., pi_{i-j}}

    pi_i := j
```

Algorithmus 2: O(2^n)
```
j := random(1, n!)
pi := j-te Permutation von n Elementen
```

Algorithmus 3: O(n log(n))
```
L1, ...., Ln zufällige Zahlen, sortieren
for i = 1 to n, do
    Li := (i, random(i, n^3))
Sigma := sort(L) anhand 2ter Komponente
for i = 1 to n do:
    pi_i := Li[0] // Erster Wert des Tupels
```

### Def m-Permutation

Sei G Menge mit n Elementen, m-Permutation ist Sequenz von m Elementen aus G.

Es gibt n! / (n-m)! m-Permutationen.

## Algorithmus: CLRS (Zufällige Permutation)

- O(n)

```
// Set p_is to (unshuffled) input
for i = 1 to n do
    p_i := i

// Shuffle p_is in-place
for i = 1 to n do
    // (*)
    k := random(i, n)
    swap(p_i, p_k)
```

Notation: Permutation S = rho

Invariante `(*)`: Vor iteration i, Für jede (i-1)-Permutation S von [1, n], die
Sequenz pi_1 ... pi_{i-1} ist gleich S mit W'keit (n-i+1)!/n!

Verankerung i=1: Jede 0-Permutation ist gleich {} mit W'keit 1

Schritt:
Sei S eine (i-1) Permutation, S = s1 ... s_{i-1}
1) P[pi_1 ... pi_{i-1} = s1 ... s_{i-1}] = (n-i+1)!/n!
2) P[Si = pi_i | pi_1 ... pi_{i-1} = s_1 ... s_{i-1}] = 1 / (n - i + 1)

1 ^ 2 => P[s1 ... si = pi_1 ... pi_i] 
      = P[s1 ... s_{i-1} | pi_1 ... pi_{i-1}] * P{si = pi_i | s1 ... s_{i-1} = pi_1 ... pi_{i-1}]
      = (n-i+1)!/n! * 1/(n-i+1)
      = (n-1)!/n!


## Def Bernoulli-ZV

Experiment gelingt mit W'keit p.
P(X=0) = 1-p, P(X=1) = p, E[X] = p

## Def Binomial-Verteilung

Anzahl von erfolgreichen Bernoulli Experimenten, bei Durchführung von n
Experimenten.

X ~ Bi(n, p) n Experimente, W'keit p,
P(X = k) = binom(n, p) * p^k * (1-p)^n-k

Es Gilt: X = Sum for i = 1 to n: X_i
Wobei X_i Bernoulli-ZV
Damit E[X] = E[Sum X_i] = Sum(E[X_i]) = Sum(p) = np
E[X] = np

## Def Geometrische Verteilung

X ~ Geom(p)
P(X=x) = (1-p)^(n-1) p
"Anzahl Versuche bis zum ersten Erfolg"

Alle Versuche unabh, dH Anzahl der bereits fehlgeschlagenen Versuche hat keinen
Einfluss auf Verteilung von X. (Nichts mit "irgendwann muss es ja klappen").

### Lemma

```
P[X=n+k | x > k] = P[X=n]
```

Geometrische Verteilung ist gedächtnislos.

#### Beweis

```
P[X=n+k | X>k] = 
P[X=n+k ^ X>k] / P[X>k]
= P[X=n+k]/P[X>k]
= (1-p)^(n+k-1)*p/(sum for i = k to infty (1-p)^i * p)
= (1-p)^(n+k-1)*p/(1-p)^k
= (1-p)^(n-1)*p = P{X=n]
```

### Lemma

```
X ~ Geom(p)
E[X] = 1/p
```

#### Bew

Entweder klassisch via gewichtete Summe, oder via Gedächtnislosigkeit:

```
X: Anzahl Versuche bis zum ersten Erfolg, X ~ Geom(p)
S: Bernoulli-ZV, sagt aus ob erster Versuch Erfolg hat, S ~ Bern(p)
E[X] = P[S=0] * E[X | S=0] + P[S=1] * P[X | S=1]
     = (1-p) * E[X | S=0] + p

Sei Z Anzahl verbleiibender Versuche im Fall S=0

E[X] = (1-p) * E[Z+1] + p // "Z zählt eines zu wenig"
     = (1-p) * E[Z] + 1 // p bewusst weg, ausmultipliziert dann weggekürzt!

Gedächtnislos => E[X] = E[Z]
Damit E[X] = (1-p) * E[X] + 1
E[X] = 1/p
```

