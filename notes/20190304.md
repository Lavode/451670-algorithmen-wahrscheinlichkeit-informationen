# 1. Ereignisse und Wahrscheinlichkeit (2019-03-04)

## Alg: VerifyMatrix

```
IN: A, B, C mxm matrices, binary
OUT: A x B =? C

r := random({0, 1}^n)
IF A(B * r) \neq C * r THEN return false
ELSE return true
```

- Kosten: O(n^2) Operationen
- Nachrechnen: O(n^3)
- Fehler: Falls A * B \neq C, aber Alg True
  - dH P[A * B * r = C * r | A * B \neq C]
  - D = A * B * C \neq 0
  - P[D * r = 0]
  - D = (d_{ij})
  - d_{nn} \neq 0 ... (?)
  - Sum i=1 to n d_{ni} * r_i = 0
  - iff r_n = 1/d_{nn} * sum i=1 to n-1 d_{ni} * r_i
  - Aufgeschobene Entscheidung: P[r_n = s | r_1 ... r_{n-1}] = 1/2
  - = P[Alg irrt] = P[VerifyMatrix(A, B, C) = TRUE | A * B \neq C]

### Wiederholungen

- Max n mal, da sonst Komplexität zu hoch
- Allgemein: Schon ab 100 Wiederholungen ist Fehlerw'keit mit (1/2)^100 verschwindend klein
  - Für praktische Probleme (zB nicht kryptographische) bereits 30 od 40 Wiederholungen genug

## Prinzip d aufgeschobenen Entscheidung

- Seien x_1 ... x_n Werte nach bestimmter Verteilung.
- Falls Verteilung von x_n nicht von x_1 ... x_{n-1} abhängt, kann für
  Betrachtung von xn davon ausgegangen werden, dass x1 ... x(n-1) bereits
  bestimmt sind.

## Alg: Minimal cut

- Gegeben Graph G = (V, E)
- Schnitt: Linie durch Graphen die Teil des Graphen "wegschneidet"
- Minimaler Schnitt: Bspw Anzahl Kanten (oder Gewichte od ...) minimal

```
IN: G = (V, E)
OUT: Mögl kleinster Schnitt C

WHILE |V| >= 2 do
  e := random(E) // Select random edge to cut
  (v1, v2) := e // vertices of randomly selected edge
  // Join v1 and v2, retain all edges in G except e, and except self-loops
  V := V \ {v1, v2} U {v12}
done

return E
```

- Schritte O(|V|)
- P[Minimaler Schritt berechnet] >= 2 / (n*(n-1)):
- Intuition:
  - Sei Gi der Graph nach i Schritten
  - Schnitt in Gi ist auch valider Schnitt in G0 ... Gi-1
    - Insbesondere Schnitt in letztem Graph (mit |V| = 2) valid in allen vorhergehenden
    - Gegenrichtung gilt nicht
  - Wenn wir bei jeider Join-Operation Kante auswählen, die nicht in minimalem
    Schnitt ist, haben wir am Ende das korrekte Ergebnis

### Theorem

Mincut berechnet kleinsten Schnitt mit WSK 2/(n*(n-1))

Sei C ein kleinster Schnitt mit |C| = k Kanten.
- Jeder Knoten mind k Kanten, denn wenn weniger, wäre C nicht der minimale Schnitt

Ai = { Kante e in Schritt i \nin C }
Bi = { Alle Kanten in Schritten 1 .. i \nin C } = A1 \cup ... \cup Ai

Algorithmus macht n-2 Schritte.

P[B_(n-2)] = WSK dass Alg Ergebnis eines Min-Cut zurückgibt

Wegen |C| = k hat jeder Knoten mindestens k Kanten => G hat > n*k/2 Kanten

P[A1] = P[B1] >= 1 - k * 2/(nk) = 1 - 2/n
  - Schritt 1 wählt zufällig

Nach i-1 Schritten hat G (n-i + 1)*k/2 Kanten
P[Ai | Bi-1] >= 1 - k * 2/((n-i+1)*k) = 1-2/(n+i+1)

P[Bn-2] = P[An-2 | Bn-3] * P[An-3 | Bn-4] * ... * P[A2 | B1] * P[B1]
= Product for i = 1 to n-2 P[Ai | Bi-1]
>= Product for i=1 to n-2 (1-2/(n-i+1)) = product i=1 to n-2 (n-i-1)/(n-1+1) = (n-2)/n * (n-3)/(n-1) * ... * 2/4 * 1/3
= 2 / (n*(n-1))

Mehrfache Ausführung möglich, für bessere Abschätzung

# 2. Zufallsvariablen und Erwaruntgswerte (2019-03-04)

Zufallsvariable (ZV) ist Abbildung aus einem WSK-Raum Omega in ein Xi (?). (Geschwungenes X)

## Def

Sei X ZV, "X \in Xi"
- Omega: WSK-Raum
- Xi: Definitionsmenge, Alphabet
- Omega -> Xi: Abbildung

### Notation

- ZV A, Def-Menge Xi
- P_A(a) = P[A = a], a \in Xi
  - = Sum for w in Omega: P[A(w) = a]

## Def Erwartungswert

- E{X} = Sum over x in Xi: x * P_X(x)

## Def Unabhängigkeit

Forall x in X, y in Y: P_XY(x, y) = P_X(x) * P_Y(y)
<=> X, Y unabhängig

Analog für n ZV, muss gelten für alle möglichen Produkte.

## Theorem

E[Sum for i = 1 to n X_i] = Sum for i = 1 to n E[X_i]

## Lemma

Für c konsant, E[c * X] = c * E[X]

## Def Konvex

f: R -> R ist  konvex iff forall x1, x2:
  Funktionsgraph an Stelle (x1+x2)/2 *unter* (oder gleich) Gerade die x1 und x2 verbindet

## Satz Jensen-Ungleichung

Für konvexe f() und ZV X:
E[f(X)] \gte f(E[X])

### Bsp

#### 1 

E[X^2] \gte E[X]^2

#### 2

Sei f() zweimal diff'bar
f() konvex iff f''() > 0

Sei mu = E[X]
f(x) = f(mu) + f'(mu) * (x - mu) + f''(c) * (x-mu)^2
f(x) \gte f(mu) * f'(mu)*(x-mu)

E[F(X)] \gte E[f(mu) + f'(mu) * (X-mu)]
= E[f(mu)] + E[f'(mu)*(X-mu)]
= E[f(mu)] + E[f'(mu)] * (E[X] - mu)
= f(mu) = f(E(X))
